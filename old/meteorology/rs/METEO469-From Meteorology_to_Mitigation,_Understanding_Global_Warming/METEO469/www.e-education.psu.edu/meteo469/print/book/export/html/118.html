
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML+RDFa 1.0//EN"
  "http://www.w3.org/MarkUp/DTD/xhtml-rdfa-1.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" version="XHTML+RDFa 1.0" dir="ltr">
  
<!-- Mirrored from www.e-education.psu.edu/meteo469/print/book/export/html/118 by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 29 Jan 2019 19:47:36 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="Generator" content="Drupal 7 (http://drupal.org)" />
    <base  />
    <title>Lesson 2 - Climate Observations, part 1</title>
    <script type="text/javascript" src="../../../../misc/jquery1cc4.js?v=1.4.4"></script>
<script type="text/javascript" src="../../../../misc/jquery.once7839.js?v=1.2"></script>
<script type="text/javascript" src="../../../../misc/drupal57c0.js?pjybv3"></script>
<script type="text/javascript" src="../../../../sites/all/modules/custom_js_libraries/printable_links/printable_links57c0.js?pjybv3"></script>
<script type="text/javascript" src="../../../../sites/all/modules/custom_js_libraries/toggler/toggler57c0.js?pjybv3"></script>
<script type="text/javascript">
<!--//--><![CDATA[//><!--
jQuery.extend(Drupal.settings, {"basePath":"\/meteo469\/","pathPrefix":"","ajaxPageState":{"theme":"esp","theme_token":"KWwknuHfeayi5qmMc9hzD_RWVh9HJ0fUiyzngs1ZB9Q","js":{"misc\/jquery.js":1,"misc\/jquery.once.js":1,"misc\/drupal.js":1,"sites\/all\/modules\/custom_js_libraries\/printable_links\/printable_links.js":1,"sites\/all\/modules\/custom_js_libraries\/toggler\/toggler.js":1}}});
//--><!]]>
</script>
        <meta name="robots" content="noindex, nofollow" />        <style type="text/css" media="all">
@import url("https://www.e-education.psu.edu/meteo469/modules/system/system.base.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/modules/system/system.menus.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/modules/system/system.messages.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/modules/system/system.theme.css?pjybv3");
</style>
<style type="text/css" media="screen">
@import url("https://www.e-education.psu.edu/meteo469/sites/all/modules/iconizer/files_icons.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/sites/all/modules/iconizer/proto_icons.css?pjybv3");
</style>
<style type="text/css" media="all">
@import url("https://www.e-education.psu.edu/meteo469/modules/book/book.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/modules/field/theme/field.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/modules/node/node.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/modules/search/search.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/modules/user/user.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/sites/all/modules/extlink/extlink.css?pjybv3");
</style>
<link type="text/css" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata:regular,700&amp;subset=latin-ext" media="all" />
<link type="text/css" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,regular,600,700&amp;subset=latin-ext" media="all" />
<link type="text/css" rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif&amp;subset=latin-ext" media="all" />
<style type="text/css" media="all">
@import url("https://www.e-education.psu.edu/meteo469/sites/all/modules/hidden_nodes/hidden_nodes.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/sites/all/modules/print/print_ui/css/print_ui.theme.css?pjybv3");
@import url("https://www.e-education.psu.edu/meteo469/sites/all/modules/print/css/print.css?pjybv3");
</style>
  </head>
  <body>
            <div class="print-site_name">Published on <em class="placeholder">METEO 469: From Meteorology to Mitigation: Understanding Global Warming D7</em> (<a href="https://www.e-education.psu.edu/meteo469">https://www.e-education.psu.edu/meteo469</a>)</div>
    <p />
    <div class="print-breadcrumb"><a href="https://www.e-education.psu.edu/meteo469/">Home</a> &gt; <a href="https://www.e-education.psu.edu/meteo469/node/111">METEO 469 Course Outline</a> &gt; Lesson 2 - Climate Observations, part 1</div>
    <hr class="print-hr" />
        <div class="print-content"><div id="node-118" class="section-2">
  <h1 class="book-heading">Lesson 2 - Climate Observations, part 1</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><p>The links below provide an outline of the material for this lesson. Be sure to carefully read through the entire lesson before returning to Canvas to submit your assignments.</p>
</div></div></div></div>  <div id="node-249" class="section-3">
  <h1 class="book-heading">Introduction</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><h3>About Lesson 2</h3>

<p>How do we know that climate change is taking place? Or that the factors we believe to be driving climate change, such as greenhouse gas concentrations, are themselves changing?</p>

<p>To address these questions, we turn first to instrumental measurements documenting changes in the properties of our atmosphere over time. These measurements are not without their uncertainties, particularly in earlier times. But they can help us to assess whether there appear to be trends in measures of climate and the factors governing climate and whether the trends are consistent with our expectations of what the response of the climate system to human impacts ought to look like.</p>

<h3>What will we learn in Lesson 2?</h3>

<p>By the end of Lesson 2, you should be able to:</p>

<ul>
	<li>Discuss the various modern observational data characterizing changes in surface and atmospheric temperature over the historical period;</li>
	<li>Discuss the nature of the uncertainties in the observational record of past climate; and</li>
	<li>Perform simple statistical analyses to characterize trends in, and relationships between, data series.</li>
</ul>

<h3>What will be due for Lesson 2?</h3>

<p><strong>Please refer to the Syllabus for the specific time frames and due dates.</strong></p>

<p>The following is an overview of the <em>required activities</em> for Lesson 2. Detailed directions and submission instructions are located within this lesson.</p>

<ul>
	<li>Read:
		<ul>
			<li><a href="https://www.ipcc.ch/report/ar5/wg1/">IPCC Fifth Assessment Report, Working Group 1</a> <span class="print-footnote">[1]</span>

				<ul>
					<li><a href="https://www.ipcc.ch/site/assets/uploads/2018/02/WG1AR5_SPM_FINAL.pdf">Summary for Policy Makers</a> <span class="print-footnote">[2]</span>

						<ul>
							<li>B Observed Changes in the Climate System: p. 4</li>
							<li>B.1 Atmosphere: p. 5-8</li>
						</ul>
					</li>
				</ul>
			</li>
			<li>Dire Predictions, v.2: p. 34-35, 38-39, 80-81</li>
		</ul>
	</li>
	<li>Problem Set #1: Perform basic statistical analyses of climate data.</li>
</ul>

<h3>Questions?</h3>

<p>If you have any questions, please post them to our <em>Questions?&nbsp; </em>discussion forum (not e-mail), located under the Home tab in Canvas. The instructor will check that discussion forum daily to respond. While you are there, feel free to post your own responses if you can help with any of the posted questions.</p>
</div></div></div></div>  </div>
<div id="node-119" class="section-3">
  <h1 class="book-heading">Observed Changes in Greenhouse Gases</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><p>Before we assess the climate data documenting changes in the climate system, we ought to address the question — is there evidence that greenhouse gases, purportedly responsible for observed warming, are actually changing in the first place?</p>

<p>Thanks to two legendary atmospheric scientists, we know that there is such evidence. The first of these scientists was <a href="http://earthobservatory.nasa.gov/Features/Revelle/revelle.php">Roger Revelle</a> <span class="print-footnote">[3]</span>.</p>

<div class="img-center"><img alt="portrait of Roger Revelle." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/Revelle.jpg">
	<div class="img-caption">Roger Revelle.</div>

	<div class="img-credit">Credit: <a href="http://www.harvardsquarelibrary.org/biographies/roger-revelle/">Cambridge Forum Speakers</a> <span class="print-footnote">[4]</span></div>
</div>

<p>Revelle, as we will later see, made fundamental contributions to understanding climate change throughout his career. Less known, but equally important, was the tutelage and mentorship that Revelle provided to other climate researchers. While at the Scripps Institution for Oceanography at the University of California in San Diego, Revelle encouraged his colleague <a href="http://scrippsco2.ucsd.edu/history_legacy/charles_david_keeling_biography">Charles David Keeling</a> <span class="print-footnote">[5]</span> to make direct measurements of atmospheric CO<sub>2</sub> levels from an appropriately selected site.</p>

<div class="box-activity-optional">
	<h4>Think About It!</h4>

	<p><strong>Why do you suppose it is adequate to make measurements of atmospheric CO<sub>2</sub> from a single location as an indication of changing global concentrations?</strong></p>
	<textarea cols="100" rows="1"></textarea>

	<p class="toggler">Click for answer.</p>

	<div class="clicktip" id="ctdef">Answer: If you said, recalling our earlier discussion from Lesson 1, that it is because the atmosphere is <em>well mixed</em> with respect to most trace gases (including CO<sub>2</sub>), then you are correct. This means that as long as you can find a relatively pristine environment (i.e., the environment that is not subject to strong local sources of CO<sub>2</sub>, as would be the case for a large city, for example), you essentially are observing the global average CO<sub>2</sub> concentration.</div>
</div>

<p>Revelle and Keeling settled on the top of the mountain peak Mauna Loa on the big island of Hawaii, establishing during the <em>International Geophysical Year</em> of 1958 an observatory that would be maintained by Keeling and his crew for the ensuing decades.</p>

<div class="img-center"><img alt="Keeling in front of the Keeling Building" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/img_scripps_Keeling97.jpg">
	<div class="img-caption">Charles David Keeling.</div>

	<div class="img-credit">Credit: <a href="http://www.esrl.noaa.gov/">NOAA</a> <span class="print-footnote">[6]</span></div>
</div>

<div class="img-center"><img alt="Outside of the Mauna Loa Observatory." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/mauna-loa-obs-3.jpg">
	<div class="img-caption">Mauna Loa Observatory.</div>

	<div class="img-credit">Credit: <a href="http://www.esrl.noaa.gov/research/themes/carbon/">NOAA</a> <span class="print-footnote">[7]</span></div>
</div>

<p>From this location, Keeling and crew would make continuous measurements of atmospheric CO<sub>2</sub> from 1958 henceforth. Since then, long-term records have been established in other locations over the globe as well. The result of Keeling's labors is arguably the most famous curve in all of atmospheric science, the so-called <em>Keeling Curve</em>. That curve shows a steady increase in atmospheric CO<sub>2</sub> concentrations from about 315 ppm when the measurements began in 1958 to over 400 ppm today (and climbing by about 2 ppm per year presently).</p>

<div class="img-center">
	<p><img alt="Graph of Atmospheric CO2 at Mauna Loa Observatory. Steady increase from 310 parts per million in 1960 to over 400 ppm in 2018." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/co2_data_mlo.png"></p>

	<div class="img-caption">Figure 2.1: Atmospheric CO<sub>2</sub> at Mauna Loa Observatory</div>

	<div class="img-credit">Credit: <a href="http://www.esrl.noaa.gov/">NOAA</a> <span class="print-footnote">[8]</span></div>
</div>

<p>You might be wondering at this point, how do we know that the increase in CO<sub>2</sub> is not natural? For one thing, as you already have encountered in your readings, the recent levels are unprecedented over many millennia. Indeed, when we cover the topic of <em>paleoclimate</em>, we will see that the modern levels are unprecedented over many <em>hundreds of thousands </em>of years, and probably several million years. We will also see that there is a long-term relationship between CO<sub>2</sub> and temperature, though the story is not as simple as you might think.</p>

<p>But there is other more direct evidence that the source of the increasing CO<sub>2 </sub>is indeed human, i.e., anthropogenic. It turns out that carbon that gets buried in the earth from dying organic matter and eventually turns into fossil fuels, tends to be <em>isotopically light</em>. That is, nature has a preference for burying carbon that is depleted of the heavier, <sup>13</sup>C, carbon isotope. Fossil fuels are thus relatively rich in the lighter isotope, <sup>12</sup>C. However, natural atmospheric CO<sub>2</sub> produced by respiration (be it animals like us, or plants which both respire and photosynthesize) tends to have a greater abundance of the heavier <sup>13</sup>C isotope of carbon. If the CO<sub>2</sub> increase were from natural sources, we would therefore expect the ratio of <sup>13</sup>C to <sup>12</sup>C to be getting higher. But instead, the ratio of <sup>13</sup>C to <sup>12</sup>C is getting lower as CO<sub>2</sub> is building up in our atmosphere -- i.e., the ratio bears the <em>fingerprint</em> of anthropogenic fossil fuel burning.</p>

<div class="img-center"><img alt="Graph of carbon-13 to carbon-12 Ratio from 1800 - 2000. ratio drops sharply around the 1990s" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/CarbonIsotopes.gif">
	<div class="img-caption">Figure 2.2: Graph of carbon-13 to carbon-12 Ratio from 1800 - 2000.</div>

	<div class="img-credit">Credit: Mann and Kump, <em>Dire Predictions: Understanding Global Warming</em> (DK, 2008, 2015)</div>
</div>

<p>Of course, CO<sub>2</sub> is not the only greenhouse gas whose concentrations are rising due to human activity. A combination of agriculture (e.g., rice cultivation), livestock raising, and dam construction led to substantial increases in methane (CH<sub>4</sub>) concentrations. Agricultural practices have also increased the concentration of nitrous oxide (N<sub>2</sub>O).</p>

<p>Using air bubbles in ice cores, we can examine small bits of atmosphere trapped in ice, as it accumulated back in time, to reconstruct the composition of the ancient atmosphere, including the past concentrations of greenhouse gases. The ice core evidence shows that the rise over the past two centuries in the concentrations of the greenhouse gases mentioned above is unprecedented for at least the past 10,000 years. Longer-term evidence suggests that concentrations are higher now than they have been for hundreds of thousands of years, and perhaps several million years.</p>

<div class="img-center"><img alt="Changes in Carbon Dioxide, Methane and Nitrous oxide record in ice cores. All 3 spike in 2014" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/GreenhouseTrends_.jpg">
	<div class="img-caption">Figure 2.3: Changes in Greenhouse Gases Record in Ice Cores.</div>

	<div class="img-credit">Credit: Mann &amp; Kump, <em>Dire Predictions: Understanding Climate Change, 2<sup>nd</sup> Edition<br>
		© 2015 Pearson Education, Inc.</em></div>
</div>

<div class="box-reading-required">
	<h3>Reading Assignment</h3>

	<p>Before we go any further, please read the following document:</p>

	<ul>
		<li>From the <a href="https://www.ipcc.ch/report/ar5/wg1/">IPCC Fifth Assessment Report, Working Group 1</a> <span class="print-footnote">[1]</span>, read section B, Observed Changes in the Climate System (p. 4), and section B.1, Atmosphere (p. 5-8) of the <a href="https://www.ipcc.ch/site/assets/uploads/2018/02/WG1AR5_SPM_FINAL.pdf">Summary for Policy Makers</a> <span class="print-footnote">[2]</span>.</li>
	</ul>

	<p>As you read, please pay particular attention to:</p>

	<ul>
		<li><em>The variety of sources of data,</em></li>
		<li><em>Internal consistency among the various data streams with regard to our changing climate.</em></li>
	</ul>
</div>
</div></div></div></div>  </div>
<div id="node-120" class="section-3">
  <h1 class="book-heading">Modern Surface Temperature Trends</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><p>Instrumental surface temperature measurements consisting of thermometer records from land-based stations, islands, and ship-board measurements of ocean surface temperatures provide us with more than a century of reasonably global estimates of surface temperature change. Some regions, like the Arctic and Antarctic, and large parts of South America, Africa, and Eurasia, were not very well sampled in earlier decades, but records in these regions become available as we move into the mid and late 20th century.</p>

<p>Temperature variations are typically measured in terms of <em>anomalies</em> relative to some <em>base period</em>. The animation below is taken from the <a href="http://data.giss.nasa.gov/gistemp/">NASA Goddard Institute for Space Studies</a> <span class="print-footnote">[9]</span> in New York (which happens to sit <a href="http://www.giss.nasa.gov/about/">just above "Tom's Diner"</a> <span class="print-footnote">[10]</span> of <em>Seinfeld </em>fame), one of several scientific institutions that monitor global temperature changes. It portrays how temperatures around the globe have changed in various regions since the late 19th century. The temperature data have been averaged into 5 year blocks, and reflect variations relative to a 1950-1980 base period, i.e., <em>warm </em>regions are warmer than the 1950-1980 average, while <em>cold</em> regions are colder than the 1950-1980 average, by the magnitudes shown. You may note a number that appears in the upper right corner of the plot. That number indicates the average temperature anomaly over the entire globe at any given time, again, relative to the 1950-1980 average.</p>

<p>Take some time to explore the animation on your own. You may want to go through it several times so you can start to get a sense of just how rich and complex the patterns of surface temperature variations are. Do you see periodic intervals of warming and cooling in the eastern equatorial Pacific? What might that be? [We will talk about the phenomenon in upcoming lessons].</p>

<p>Take note of any particularly interesting patterns in space and time that you see as you review the animation. You can turn your sound off the first few times so you do not hear the annotation of the animation. Then, when you are ready, turn the sound on and you can hear Michael Mann's take.</p>

<div class="img-center">
	<div class="video-wrapper"><iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/XqmNAhJB1LA" width="560"></iframe></div>

	<div class="img-caption">Surface Temperature Patterns</div>

	<div aria-label="expand content" class="toggler">Click here for a transcript</div>

	<div aria-label="additional content">
		<p>Let's look at the pattern of surface temperature changes over the past century. We are looking at surface temperatures relative to a base period from 1951 to 1980. So we're looking at whether the temperatures are warmer or colder than the average temperature over that late 20th century baseline. And we're looking at five year chunks.</p>

		<p>We can see that in the 1930s, for example, there was some warming at high latitudes but not global in nature. We can see that in later decades, the 1960s to 1970s, there was some cooling over large parts of the northern hemisphere, but we'll talk about that later on in the course. That might have had in part a component due to aerosol production by human activity. And of course, as we get into the late 20th century, we see large scale warming that is unprecedented over at least the period covered by the instrumental record.</p>
	</div>

	<div class="img-credit">Credit: <a href="http://data.giss.nasa.gov/gistemp/animations/">NASA's Goddard Institute for Space Studies</a> <span class="print-footnote">[11]</span></div>
</div>

<p>We can average over the entire globe for any given year and get a single number, the global average temperature. Here is the curve we get if we plot out that quantity. Note that in the plot below the average temperature over the base period has been added to the anomalies, so that the estimate reflects the surface temperature of the Earth itself.</p>

<div class="img-center"><img alt="Global average surface temp. 1860-2015; also includes long-term trend increase .01C/year and 25 year trend increase .02C/year" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/GlobalMeanTempDP_.jpg" style="width: 650px; height: 287px;">
	<div class="img-caption">Figure 2.4: Trends in Global Average Surface Temp. 1860-2015.</div>

	<div class="img-credit">Credit: Mann &amp; Kump, <em>Dire Predictions: Understanding Climate Change, 2<sup>nd</sup> Edition<br>
		© 2015 Pearson Education, Inc.</em></div>
</div>

<p>We can see that the Earth has warmed a little less than 1°C (about 1.5 F) since widespread records became available in the mid-19th century. That this warming has taken place is essentially incontrovertible from a scientific point of view. What is the <em>cause</em> of this warming? That is a more difficult question, which we will address later.</p>

<p>We discussed above the cooling that is evident in parts of the Northern Hemisphere (particularly over the land masses) from the 1940s-1970s. There was a time during the mid 1970s, when <em>some</em> scientists thought the globe might be entering into a long-term <em>cooling trend</em>. There was a reason to believe that might be the case. In the absence of other factors, changes in the Earth's orbital geometry did favor the descent (albeit a very slow one!) into the next ice age. Also, the buildup of atmospheric aerosols, which, as we will explore, can have a large regional cooling impact, favored cooling. Precisely how these cooling effects would balance out against the warming impact of greenhouse gases was not known at the time.</p>

<p>Some critics claim that if the scientific community thought were were entering into another Ice Age in the 1970s, why should we trust the scientists now about global warming? In fact, it was <a href="http://www.realclimate.org/index.php/archives/2008/03/the-global-cooling-mole/">far from a scientific consensus</a> <span class="print-footnote">[12]</span> within the scientific community in the mid 1970s that we were headed into another Ice Age. Some scientists speculated this was possible, but the prevailing viewpoint was that increasing greenhouse gas concentrations and warming would likely win out.</p>

<p>We know that, indeed, the short term cooling trend for the Northern Hemisphere continents ended in the 1970s, and, since then, global warming has dominated over any cooling effects.</p>

<div class="img-center"><img alt="N Hemisphere Continental Temp Trends 1860 - 2000. Shows sharp rise since 1970." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/NHLandTempsDP_.jpg">
	<div class="img-caption">Figure 2.5: Northern Hemisphere Continental Temperature Trends.</div>

	<div class="img-credit">Credit: Mann &amp; Kump, <em>Dire Predictions: Understanding Climate Change, 2<sup>nd</sup> Edition<br>
		© 2015 Pearson Education, Inc.</em></div>
</div>

<p>As mentioned earlier, we cannot deduce the <em>cause</em> of the observed warming solely from the fact that the globe is warming. However, we can look for possible clues. Just like forensics experts, climate scientists refer to these clues as<em> fingerprints</em>. It turns out that natural sources of warming give rise to different patterns of temperature change than human sources, such as increasing greenhouse gases. This is particularly true when we look at the <em>vertical pattern</em> of warming in the atmosphere. This is our next topic.</p>
</div></div></div></div>  </div>
<div id="node-121" class="section-3">
  <h1 class="book-heading">Vertical Temperature Trends</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><p>As alluded to previously, the vertical pattern of observed atmospheric temperature trends provides some important clues in establishing the underlying cause of the warming. While upper air temperature estimates (from weather balloons and satellite measurements) are only available for the latter half of the past century, they reveal a remarkable pattern. The lower part of the atmosphere — the <em>troposphere,</em> has been warming along with the surface. However, once we get into the <em>stratosphere</em>, the temperatures have actually been decreasing! As we will learn later when we focus on the problem of climate signal <em>fingerprinting</em>, certain forcings are consistent with such a vertical pattern of temperature changes, while other forcings are not.</p>

<div class="img-center"><img alt="Infographic of air temperature analysis of 20th century atmospheric changes. Greatest warming in tropics and troposphere. Stratosphere decreases" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/VerticalTrendsDP_small_.jpg">
	<div class="img-caption">Figure 2.6: Recent Temperature Trends at Various Levels in the Atmosphere. These graphs show observed temperature trends at various altitudes in the atmosphere from lower stratosphere to mid to upper troposphere. The graphic on the right shows the pattern of 20th century atmospheric temperature changes predicted by climate models. Note that the gratest warming is observed in the tropics and in the lower atmosphere.</div>

	<div class="img-credit">Credit: Mann &amp; Kump, <em>Dire Predictions: Understanding Climate Change, 2<sup>nd</sup> Edition<br>
		© 2015 Pearson Education Inc.</em></div>
</div>

<div class="box-activity-optional">
	<h4>Think About It!</h4>

	<p><strong>Care to venture a guess as to which forcing might be most consistent with this vertical pattern of temperature change?</strong></p>
	<textarea cols="100" rows="1"></textarea>

	<p class="toggler">Click for answer.</p>

	<div class="clicktip" id="ctdef">If you said "increased greenhouse gas concentrations", you are correct.<br>
		We will later see why this explanation is consistent with the observed pattern of warming, while other explanations, such as natural changes in solar output, are not.</div>
</div>
</div></div></div></div>  </div>
<div id="node-122" class="section-3">
  <h1 class="book-heading">Historical Variations in Precipitation and Drought</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><p>Recall our discussion of the <a href="https://www.e-education.psu.edu/meteo469/node/203">general circulation of the atmosphere</a> <span class="print-footnote">[13]</span> from Lesson #1.</p>

<p>There we learned that the circulation of the atmosphere is driven by the contrast in surface heating between the equator and the poles. That contrast results from the difference between incoming short wave solar heating and outgoing loss from the surface through various modes of energy transport including radiational heat loss as well as heat loss through convection and latent heat release through evaporation.</p>

<p>It, therefore, stands to reason that climate change — which in principle involves changing the balance between incoming and outgoing radiative loss via changes in the greenhouse effect — is likely to alter the circulation of the atmosphere itself, and thus, large-scale precipitation patterns. The observed changes in precipitation patterns are far <em>noisier</em> (very variable and difficult to interpret) than temperature changes, however.&nbsp; Regional effects related to topography (e.g., mountain ranges that force air upward leading to wet windward and dry leeward conditions),&nbsp;&nbsp; ocean-atmosphere heating contrasts that drive regional circulation patterns, such as monsoons, etc., lead to very heterogeneous patterns of changes in rainfall, in comparison with the pattern of surface temperature changes.</p>

<div class="img-center"><img alt="World map showing regional trends in annual precipitation, 1901-2005. Trends discussed in surrounding text" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/PrecipTrendsIPCC_small.gif">
	<div class="img-caption">Figure 2.7: Trends in Annual Precipitation, 1901-2005 [<a href="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/PrecipTrendsIPCC_large.gif">Enlarge</a> <span class="print-footnote">[14]</span>].</div>

	<div class="img-credit">Credit:&nbsp; IPCC Fourth Assessment Report, Chapter 3, Figure 3.14</div>
</div>

<p>We might expect certain reasonably simple patterns to emerge, nonetheless. As we shall see <a href="https://www.e-education.psu.edu/meteo469/node/152">in a later lesson </a> <span class="print-footnote">[15]</span>looking at climate change projections, climate models predict that atmospheric circulation cells and storm tracks migrate poleward, shifting patterns of rainfall between the equator and poles. The subtropics and middle latitudes tend to get dryer, while the sub-polar latitudes get wetter (primarily in winter). The equatorial region actually is predicted to get wetter, simply because the rising motion that occurs there squeezes out more rainfall from the warmer, moister lower atmosphere. If we average the observed precipitation changes in terms of trends in different latitudinal bands, we can see some evidence of the changes.</p>

<div class="img-center"><img alt="Changes over Time in Precipitation For Various Latitude Bands 1900 - 2000. 1900-'60 are wetter at 20*N After 1960 most areas are 0-5% drier" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/IPCCfigure3-15-l.gif">
	<div class="img-caption">Figure 2.8: Changes over Time in Precipitation For Various Latitude Bands</div>

	<div class="img-credit">Credit: IPCC Fourth Assessment Report, Chapter 3, Figure 3.15</div>
</div>

<p>For example, we see that over time the high northern latitudes (60-80N) are getting wetter, while the subtropical and middle latitudes of the Northern Hemisphere are getting dryer. However, there is a lot of variability from year to year, and from decade to decade, making it difficult to clearly discern whether the theoretically predicted changes are yet evident.</p>

<p>Drought, as we will see, does not simply follow rainfall changes. Rather, it reflects a combination of both rainfall and temperature influences. Decreased rainfall can lead to warmer ground temperatures, increased evaporation from the surface, decreased soil moisture, and thus drying.</p>

<p>Like rainfall, regional patterns of drought are complicated and influenced by a number of different factors. However, the combination of shifting rainfall patterns and increased evaporation has led to very pronounced increases in drought in subtropical regions, and even in many tropical and sub-polar regions, where rainfall shows little trend (as indicated in the earlier graphic) but warmer temperatures have led to decreased soil moisture. These broad trends are seen in measurements of the <em>Palmer Drought Severity Index</em> -- an index that combines the effects of changing rainfall and temperature to estimate soil moisture content; the more negative the index, the stronger the drought.</p>

<div class="img-center"><img alt="Graph showing the Decadal drought average 1900-2000 rising above average after 1960 and stabilizing at above average around 1990" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/DroughtSeriesDP.gif">
	<div class="img-caption">Figure 2.9: Evolution of Drought Pattern.</div>

	<div class="img-credit">Credit: Pearson, 2009</div>
</div>

<div class="img-center"><img alt="map of global drought pattern measured by the palmer drought severity index. Driest in Africa and middle east, S. Europe &amp; Canada " src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/DroughtPatternDP.gif">
	<div class="img-caption">Figure 2.10: Global Pattern of Drought, as Measured by the Palmer Drought Severity Index.</div>

	<div class="img-credit">Credit: Pearson, 2009</div>
</div>

<p>In the next lesson, we will assess evidence for changes in extreme weather events, such as heat waves, floods, tropical cyclone activity, etc. In the meantime, however, we are going to digress a bit and discuss the topic of how to analyze data for inferences into such matters as discerning whether or not trends are evident in particular data sets, and whether it is possible to establish a relationship between two or more different data sets.</p>
</div></div></div></div>  </div>
<div id="node-123" class="section-3">
  <h1 class="book-heading">Review of Basic Statistical Analysis Methods for Analyzing Data - Part 1</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><p>Now that we have looked at the basic data, we need to talk about how to <em>analyze</em> the data to make inferences about what they may tell us.</p>

<p>The sorts of questions we might want to answer are:</p>

<ul>
	<li>Do the data indicate a<em> trend</em>?</li>
	<li>Is there an apparent <em>relationship</em> between two or more different data sets?</li>
</ul>

<p>These sorts of questions may seem simple, but they are not. They require us, first of all, to introduce the concept of <em>hypothesis testing</em>.</p>

<p>To ask questions of a data set, one has to first formalize the question in a meaningful way. For example, if we want to know whether or not a data series, such as global average temperatures, display a trend, we need to think carefully about what it means to say that a data series has a trend!</p>

<p>This leads us to consider the concept of the <em>null hypothesis</em>. The null hypothesis states what we would expect purely from chance alone, in the absence of anything interesting (such as a trend) in the data. In many circumstances, the null hypothesis is that the data are the product of being randomly drawn from a <em>normal distribution</em>, what is often called a <em>bell curve</em>, or sometimes, a <em>Gaussian distribution</em> (after the great mathematician <a href="http://en.wikipedia.org/wiki/Carl_Friedrich_Gauss">Carl Friedrich Gauss</a> <span class="print-footnote">[16]</span>):</p>

<div class="img-center"><img alt="A bell curve (Gaussian Distribution)." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson01/gaussian.gif">
	<div class="img-caption">Figure 2.11: Gaussian Distribution.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>In the normal distribution shown above, the average or <em>mean</em> of the data set has been set to zero (that is where the peak is centered), and the <em>standard deviation</em> (<em>s.d</em>.), a measure of the typical amplitude of the fluctuations, is set to one. If we draw random samples from such a distribution, then roughly 68% of the time the values will fall within 1 s.d. of the mean (in the above example, that is the range -1 to +1). That means that roughly 16% of the time the data will fall above 1 s.d., and roughly 16% of the time the data will fall below 1 s.d. About 95% of the time, the randomly drawn values will fall within 2 s.d. (i.e., the range -2 to +2 in the above example). That means only 2.5% of the time the data will fall above 2 s.d. and only 2.5% of the time below 2 s.d. For this reason, the 2 s.d. (or <em>2 sigma</em>) range, is often used to characterize the region we are relatively confident the data should fall in, and the data that fall outside that range are candidates for potentially interesting anomalies.</p>

<h3>Random Time Series</h3>

<p>Here is an example of what a random data series of length <em>N</em> = 200 which we will call ε(<em>t</em>), drawn from a simple normal distribution with mean zero and standard deviation one looks like (for example, you can think of this data set as a 200 year long temperature anomaly record).</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msub> <mi>Y</mi> <mi>t</mi> </msub> <mo>=</mo><mi>ε</mi><mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow></mrow> </math></div>

<div class="box-math-caption">(1)</div>

<div class="box-math-clear"></div>

<p>This sort of noise is called <em>white noise</em> because there is no particular preference for either higher-frequency or lower-frequency fluctuations. The fluctuations have equal amplitude.</p>

<div class="img-center"><img alt="graph of white noise. Jagged line with skinny, tightly packed peaks  " src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/whitenoise_l.gif">
	<div class="img-caption">Figure 2.12(1). <em>N</em>=200 years of Gaussian White Noise.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>There is another form of random noise, known as <em>red noise</em> because the long-term fluctuations have a greater relative magnitude than short-term fluctuations (just as red light is dominated by low-frequency visible wavelengths of light).</p>

<p>A simple model for Gaussian red noise takes the form</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msub> <mi>Y</mi> <mi>t</mi> </msub> <mo>=</mo><mi>ρ</mi><mo>⋅</mo><msub> <mi>Y</mi> <mi>t-1</mi> </msub><mo></mo><mn></mn><mo>+</mo><mi>ε</mi><mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow></mrow> </math></div>

<div class="box-math-caption">(2)</div>

<div class="box-math-clear"></div>

<p>where ε(<em>t</em>) is Gaussian white noise. As you can see, a red noise process tends to integrate the white noise over time. It is this process of integration that leads to more long-term variation than would be expected for a pure white noise series. Visually, we can see that the variations from one year to the next are not nearly as erratic. This means that the data have fewer <em>degrees of freedom (</em><em>N'</em> ) than there are actual data points (<em>N</em>). In fact, there is a simple formula relating <em>N'</em> and <em>N</em>:</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msup> <mi>N</mi> <mn>'</mn> </msup> <mo>=</mo><mi>N</mi><mfrac> <mrow> <mn>1</mn><mo>−</mo><mi>ρ</mi></mrow> <mrow> <mn>1</mn><mo>+</mo><mi>ρ</mi></mrow> </mfrac> </mrow> </math></div>

<div class="box-math-caption">(3)</div>

<div class="box-math-clear"></div>

<p>The factor <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mrow><mo>(</mo> <mrow> <mn>1</mn><mo>−</mo><mi>ρ</mi></mrow> <mo>)</mo></mrow><mo>/</mo><mrow><mo>(</mo> <mrow> <mn>1</mn><mo>+</mo><mi>ρ</mi></mrow> <mo>)</mo></mrow></mrow> </math> measures the "redness" of the noise. Let us consider again a random sequence of length <em>N</em> = 200 but this time it is "red" with the value ρ = 0.6. The same random white noise sequence used previously is used in equation 2 for ε(<em>t</em>):</p>

<div class="img-center"><img alt="graph of red noise: jagged line with wider spaced peaks " src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/rednoise_l.gif">
	<div class="img-caption">Figure 2.12(2): <em>N</em>=200 years of Gaussian 'red noise' with ρ=0.6</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<div class="box-activity-optional">
	<h4>Self-Check</h4>

	<p><strong>How many distinct peaks and troughs can you see in the series now?</strong></p>
	<textarea cols="100" rows="1"></textarea>

	<p class="toggler">Click for answer.</p>

	<div class="clicktip" id="ctdef">This is a bit subjective.<br>
		I counted about 55 distinct peaks and troughs in the series.</div>
</div>

<div class="box-activity-optional">
	<h4>Self-Check</h4>

	<p><strong>How many degrees of freedom <em>N</em> ' are there in this series?</strong></p>
	<textarea cols="100" rows="1"></textarea>

	<p class="toggler">Click for answer.</p>

	<div class="clicktip" id="ctdef">Using equation 3 above, we calculate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>N</mi><mo>'</mo><mtext>&nbsp;</mtext><mo>=</mo><mtext>&nbsp;</mtext><mrow><mo>[</mo> <mrow> <mrow><mo>(</mo> <mrow> <mn>1</mn><mtext>&nbsp;</mtext><mo>−</mo><mtext>&nbsp;</mtext><mn>0.6</mn></mrow> <mo>)</mo></mrow><mo>/</mo><mrow><mo>(</mo> <mrow> <mn>1.6</mn></mrow> <mo>)</mo></mrow></mrow> <mo>]</mo></mrow><mi>N</mi><mo>&nbsp;</mo><mo>=</mo><mn>0.25</mn><mi>N</mi><mo>=</mo><mn>0.25</mn><mo>×</mo><mn>200</mn><mo>=</mo><mn>50</mn></mrow> </math>.<br>
		That's how many <em>effective degrees of freedom</em> there are in this red noise series.<br>
		This is roughly the number of troughs and peaks you should have estimated above by eyeballing the time series!</div>
</div>

<p>As ρ gets larger and larger, and approaches one, the low-frequency fluctuations become larger and larger. In the limit where ρ = 1, we have what is known as a <em>random walk</em> or <em>Brownian motion</em>. Equation 2 in this case becomes just:</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msub> <mi>y</mi> <mi>t</mi> </msub> <mo>=</mo><msub> <mi>y</mi> <mrow> <mi>t</mi><mo>−</mo><mn>1</mn></mrow> </msub> <mo>+</mo><mi>ε</mi><mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow></mrow> </math></div>

<div class="box-math-caption">(4)</div>

<div class="box-math-clear"></div>

<p>You might notice a problem when using equation 3 in this case. For ρ = 1, we have <em>N'</em> = 0! There are no longer any effective degrees of freedom in the time series. That might seem nonsensical. But there are other attributes that make this a rather odd case as well. The time series, it turns out, now has an infinite <em>standard deviation</em>!</p>

<p>Let's look at what our original time series looks like when we now use ρ = 1:</p>

<div class="img-center"><img alt="graph of red noise with a random walk: jagged with wide peaks, decreasing amplitude" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/randomwalk_l.gif">
	<div class="img-caption">Figure 2.12(3): <em>N</em>=200 years of Gaussian 'red noise' with ρ=1, i.e., a 'random walk'.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>As you can see, the series starts out in the same place, but immediately begins making increasingly large amplitude long-term excursions up and down. It might look as if the series wants to stay negative. But if we were to continue the series further, it would eventually oscillate erratically between increasingly large <em>negative</em> <em>and positive</em> swings. Let's extend the series out to <em>N </em>= 1000 values to see that:</p>

<div class="img-center"><img alt="graph of a random walk, increasing amplitude" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/randomwalklong_l.gif">
	<div class="img-caption">Figure 2.12(4): <em>N</em>=1000 years 'random walk'.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>The swings are getting wider and wider, and they are occurring in both the positive and negative direction. Eventually, the amplitude of the swings will become arbitrarily large, i.e., infinite, even though the series will remain centered about a mean value of zero. This is an example of what we refer to in statistics as a <em>pathological </em>case.</p>

<p>Now let's look at what the original <em>N</em> = 200 long pure white noise series look like when there is a simple linear trend of 0.5 degree/century added on:</p>

<div class="img-center"><img alt="graph of Gaussian White Noise with linear trend added." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/whitenoisehastrend_l.gif">
	<div class="img-caption">Figure 2.12(5). <em>N</em>=200 years of Gaussian White Noise with linear trend added.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>Can you see a trend? In what direction? Is there a simple way to determine whether there is indeed a trend in the data that is distinguishable from random noise. That is our next topic.</p>
</div></div></div></div>  </div>
<div id="node-208" class="section-3">
  <h1 class="book-heading">Review of Basic Statistical Analysis Methods for Analyzing Data - Part 2</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><h3>Establishing Trends</h3>

<p>Various statistical hypothesis tests have been developed for exploring whether there is something more interesting in one or more data sets than would be expected from the chance fluctuations Gaussian noise. The simplest of these tests is known as <em>linear regression</em> or <em>ordinary least squares</em>. We will not go into very much detail about the underlying statistical foundations of the approach, but if you are looking for a <a href="http://en.wikipedia.org/wiki/Ordinary_least_squares">decent tutorial</a> <span class="print-footnote">[17]</span>, you can find it on Wikipedia.</p>

<p>The basic idea is that we test for an alternative hypothesis that posits a linear relationship between the <em>independent variable</em> (e.g., time, <em>t</em> in the past examples, but for purposes that will later become clear, we will call it <em>x</em>) and the<em> dependent variable</em> (i.e., the hypothetical temperature anomalies we have been looking at, but we will use the generic variable <em>y</em>).</p>

<p>The underlying statistical model for the data is:</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msub> <mi>y</mi> <mi>i</mi> </msub> <mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo>⋅</mo><msub> <mi>χ</mi> <mi>i</mi> </msub> <mo>+</mo><msub> <mi>ε</mi> <mi>i</mi> </msub> </mrow> </math></div>

<div class="box-math-caption">(5)</div>

<div class="box-math-clear"></div>

<p>where i ranges from 1 to <em>N, </em><em>a</em> is the intercept of the linear relationship between <em>y</em> and <em>x</em>, <em>b</em> is the slope of that relationship, and ε is a random noise sequence. The simplest assumption is that ε is Gaussian white noise, but we will be forced to relax that assumption at times.</p>

<p>Linear regression determines the best fit values of <em>a</em> and<em> b</em> to the given data by minimizing the <em>sum of the squared differences</em> between the observations <em>y</em> and the values predicted by the linear model <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mover accent="true"> <mi>y</mi> <mo>^</mo> </mover> <mo>=</mo><mi>a</mi><mo>+</mo><mi>b</mi><mi>x</mi></mrow> </math>. The <em>residuals</em> are our estimate of the variation in the data that is not accounted for by the linear relationship, and are defined by</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mtext> </mtext><msub> <mi>ε</mi> <mi>i</mi> </msub> <mo>=</mo><msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo><msub> <mover accent="true"> <mi>y</mi> <mo>^</mo> </mover> <mi>i</mi> </msub> </mrow> </math></div>

<div class="box-math-caption">(6)</div>

<div class="box-math-clear"></div>

<p>For simple linear regression, i.e., <em>ordinary least squares</em>, the estimates of <em>a</em> and <em>b</em> are readily obtained:</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>b</mi><mo>=</mo><mfrac> <mrow> <mrow><mo>[</mo> <mrow> <mi>N</mi><mo>⋅</mo><mi>Σ</mi><msub> <mi>y</mi> <mi>i</mi> </msub> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>−</mo><mi>Σ</mi><msub> <mi>y</mi> <mi>i</mi> </msub> <mo>⋅</mo><mi>Σ</mi><msub> <mi>x</mi> <mi>i</mi> </msub> </mrow> <mo>]</mo></mrow></mrow> <mrow> <mrow><mo>[</mo> <mrow> <mi>N</mi><mo>⋅</mo><mi>Σ</mi><msub> <mi>x</mi> <mi>i</mi> </msub> <msup> <mrow></mrow> <mn>2</mn> </msup> <mo>−</mo><mi>Σ</mi><msup> <mrow> <mrow><mo>(</mo> <mrow> <msub> <mi>x</mi> <mi>i</mi> </msub> </mrow> <mo>)</mo></mrow></mrow> <mn>2</mn> </msup> </mrow> <mo>]</mo></mrow></mrow> </mfrac> </mrow> </math></div>

<div class="box-math-caption">(7)</div>

<div class="box-math-clear"></div>

<p>and</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>a</mi><mo>=</mo><mrow><mo>(</mo> <mrow> <mfrac bevelled="true"> <mn>1</mn> <mi>N</mi> </mfrac> </mrow> <mo>)</mo></mrow><mo>⋅</mo><mi>Σ</mi><msub> <mi>y</mi> <mi>i</mi> </msub> <mo>−</mo><mfrac> <mi>b</mi> <mrow> <mi>N</mi><mo>⋅</mo><mi>Σ</mi><msub> <mi>x</mi> <mi>i</mi> </msub> </mrow> </mfrac> </mrow> </math></div>

<div class="box-math-caption">(8)</div>

<div class="box-math-clear"></div>

<p>The parameter we are most interested in is <em>b</em>, since this is what determines whether or not there is a significant linear relationship between <em>y</em> and <em>x</em>.</p>

<p>The sampling uncertainty in <em>b</em> can also be readily obtained:</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msub> <mi>σ</mi> <mi>b</mi> </msub> <mo>=</mo><mfrac> <mrow> <mi>s</mi><mi>t</mi><mi>d</mi><mrow><mo>(</mo> <mi>ε</mi> <mo>)</mo></mrow></mrow> <mrow> <msup> <mrow> <mrow><mo>[</mo> <mrow> <mi>Σ</mi><msup> <mrow> <mrow><mo>(</mo> <mrow> <msub> <mi>x</mi> <mi>i</mi> </msub> <mo>−</mo><mi>μ</mi><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow> <mo>)</mo></mrow></mrow> <mn>2</mn> </msup> </mrow> <mo>]</mo></mrow></mrow> <mrow> <mfrac> <mn>1</mn> <mn>2</mn> </mfrac> </mrow> </msup> </mrow> </mfrac> </mrow> </math></div>

<div class="box-math-caption">(9)</div>

<div class="box-math-clear"></div>

<p>where std(ε) is standard deviation of<strong> </strong>ε<strong> </strong>and μ is the mean of <em>x</em>. A statistically significant trend amounts to the finding that <em>b</em> is significantly different from zero. The 95% confidence range for <em>b</em> is given by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mo> </mo><mi>b</mi><mo>±</mo><mn>2</mn><mtext> </mtext><msub> <mi>σ</mi> <mi>b</mi> </msub> </mrow> </math> . If this interval does not cross zero, then one can conclude that <em>b</em> is significantly different from zero. We can alternatively measure the significance in terms of the <em>linear correlation coefficient</em>, <em>r</em> , between the independent and dependent variables which is related to <em>b</em> through</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>r</mi><mo>=</mo><mi>b</mi><mo>⋅</mo><mfrac> <mrow> <mi>s</mi><mi>t</mi><mi>d</mi><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow> <mrow> <mi>s</mi><mi>t</mi><mi>d</mi><mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow></mrow> </mfrac> </mrow> </math></div>

<div class="box-math-caption">(10)</div>

<div class="box-math-clear"></div>

<p><em>r</em> is readily calculated directly from the data:</p>

<div class="box-math"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>r</mi><mo>=</mo><mfrac> <mrow> <mrow><mo>(</mo> <mrow> <mfrac bevelled="true"> <mn>1</mn> <mrow> <mi>N</mi><mo>−</mo><mn>1</mn></mrow> </mfrac> </mrow> <mo>)</mo></mrow><mo>⋅</mo><mi>Σ</mi><mrow><mo>(</mo> <mrow> <mi>x</mi><mo>−</mo><mover accent="true"> <mi>x</mi> <mo>¯</mo> </mover> </mrow> <mo>)</mo></mrow><mrow><mo>(</mo> <mrow> <mi>y</mi><mo>−</mo><mover accent="true"> <mi>y</mi> <mo>¯</mo> </mover> </mrow> <mo>)</mo></mrow></mrow> <mrow> <mi>s</mi><mi>t</mi><mi>d</mi><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow><mo>⋅</mo><mi>s</mi><mi>t</mi><mi>d</mi><mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow></mrow> </mfrac> </mrow> </math></div>

<div class="box-math-caption">(11)</div>

<div class="box-math-clear"></div>

<p>where over-bar indicated the mean. Unlike <em>b</em>, which has dimensions (e.g., °C per year in the case where <em>y</em> is temperature and <em>x</em> is time), <em>r </em>is conveniently a dimensionless number whose absolute value is between 0 and 1. The larger the value of <em>r</em> (either positive or negative), the more significant is the trend. In fact, the square of <em>r</em> (<em>r</em><sup>2</sup>) is a measure of the fraction of variation in the data that is accounted for by the trend.</p>

<p>We measure the significance of any detected trends in terms of a a <em>p</em>-value. The <em>p</em>-value is an estimate of the probability that we would wrongly reject the <em>null hypothesis</em> that there is no trend in the data in favor of the <em>alternative hypothesis</em> that there is a linear trend in the data — the <em>signal</em> that we are searching for in this case. Therefore, the smaller the <em>p</em> value, the less likely that you would observe as large a trend as is found in the data from random fluctuations alone. By convention, one often requires that <em>p</em>&lt;0.05 to conclude that there is a significant trend (i.e., that only 5% of the time should such a trend have occurred from chance alone), but that is not a magic number.</p>

<p>The choice of <em>p</em> in statistical hypothesis testing represents a balance between the acceptable level of <em>false positives</em> vs. <em>false negatives</em>. In terms of our example, a false positive would be detecting a statistically significant trend, when, in fact, there is no trend; a false negative would be concluding that there is no statistically significant trend, when, in fact, there is a trend. A lower threshold (that is, higher <em>p</em>-value, e.g., <em>p</em> = 0.10) makes it more likely to detect a real but weak signal, but also more likely to falsely conclude that there is a real trend when there is not. Conversely, a higher threshold (that is, lower p-value, e.g., <em>p</em> = 0.01) makes false positives less likely, but also makes it less likely to detect a weak but real signal.</p>

<p>There are a few other important considerations. There are often two different alternative hypotheses that might be invoked. In this case, if there is a trend in the data, who is to say whether it should be positive (<em>b</em> &gt; 0) or negative (<em>b</em> &lt; 0)? In some cases, we might want only to know whether or not there is a trend, and we do not care what sign it has. We would then be invoking a <em>two-sided hypothesis</em>: is the slope <em>b</em> large enough in magnitude to conclude that it is significantly different from zero (whether positive or negative)? We would obtain a <em>p</em>-value based on the assumption of a two-sided hypothesis test. On the other hand, suppose we were testing the hypothesis that temperatures were warming due to increased greenhouse gas concentrations. In that case, we would reject a negative trend as being unphysical — inconsistent with our <em>a priori </em>understanding that increased greenhouse gas concentrations should lead to significant <em>warming</em>. In this case, we would be invoking a one-sided hypothesis. The results of a one-sided test will double the significance compared with the corresponding two-sided test, because we are throwing out as unphysical half of the random events (chance negative trends). So, if we obtain, for a given value of <em>b</em> (or <em>r</em>) a <em>p</em>-value of <em>p </em>= 0.1 for the two-sided test, than the <em>p</em>-value would be <em>p</em> = 0.05 for the corresponding one-sided test.</p>

<p><strong>There is a nice <a href="http://vassarstats.net/tabs.html">online calculator</a> <span class="print-footnote">[18]</span>, courtesy of Vassar college, for obtaining a <em>p</em>-value (both one-sided and two-sided) given the linear correlation coefficient, <em>r</em> , and the length of the data series, <em>N</em>.</strong> There is still one catch, however. If the residual<em> series</em> ε of equation 6 contains <em>autocorrelation</em>, then we have to correct the degrees of freedom, <em>N'</em>, which is less than the nominal number of data points, <em>N</em>. The correction can be made, at least approximately in many instances, using the<em> lag-one autocorrelation coefficient</em>. This is simply the linear correlation coefficient, <em>r</em><sub>1,</sub><em> </em>between ε, and a carbon copy of ε lagged by one time step. In fact, <em>r</em><sub>1</sub> provides an approximation to the parameter <strong>ρ</strong> introduced in equation 2. If<em> </em><em>r</em><sub>1</sub> is found to be positive and statistically significant (this can be checked using the online link provided above), then we can conclude that there is a statistically significant level of<em> autocorrelation</em> in our residuals, which must be corrected for. For a series of length <em>N</em> = 100, using a one-sided significant criterion of <em>p</em> = 0.05, we would need <em>r</em><sub>1 </sub>&gt; 0.17 to conclude that there is significant autocorrelation in our residuals.</p>

<p>Fortunately, the fix is very simple. If we find a positive and statistically significant value of <em>r</em><sub>1</sub>, then we can use the same significance criterion for our trend analysis described earlier, except we have to evaluate the significance of the value of<em> r</em> for our linear regression analysis (not to be confused with the autocorrelation of residuals <em>r</em><sub>1</sub>) using a reduced, effective degrees of freedom <em>N'</em>, rather than the nominal sample size <em>N</em>. Moreover, <em>N'</em> is none other than the <em>N'</em> given earlier in equation 3 where we equate <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mstyle mathsize="normal" mathvariant="inline"><mi>ρ</mi></mstyle><mo> </mo><mo>=</mo><mo> </mo><msub> <mi>r</mi> <mn>1</mn> </msub></mrow></math></p>

<p>That's about it for <strong>ordinary least squares</strong> (<strong>OLS</strong>), the main statistical tool we will use in this course. Later, we will encounter the more complicated case where there may be <em>multiple independent variables</em>. For the time being, however, let us consider the problem of trend analysis, returning to the synthetic data series discussed earlier. We will continue to imagine that the dependent variable (<em>y</em>) is temperature <em>T</em> in °C and the independent variable (<em>x</em>) is time <em>t</em> in years.</p>

<p>First, let us calculate the trend in the original Gaussian white noise series of length <em>N</em> = 200 shown in Figure 2.12(1). The linear trend is shown below:</p>

<div class="img-center"><img alt="Gaussian White Noise with linear trend shown." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/whitenoiseshowntrend_l.gif">
	<div class="img-caption">Figure 2.12(6): <em>N</em>=200 years of Gaussian White Noise with linear trend shown.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>The trend line is given by: <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mover accent="true"> <mi>T</mi> <mo>^</mo> </mover> <mo>=</mo><mn>0.0006</mn><mo>⋅</mo><mi>t</mi><mo>−</mo><mn>0.1140</mn></mrow> </math>, and the regression gives <em>r</em> = 0.0332. So there is an apparent positive warming trend of 0.0006 °C per year, or alternatively, 0.06 °C per century. Is that statistically significant? It does not sound very impressive, does it? And that <em>r</em> looks pretty small! But let us be rigorous about this. We have<em> N </em>= 200, and if we use the online calculator link provided above, we get a <em>p</em>-value of 0.64 for the (default) two-sided hypothesis. That is huge, implying that we would be foolish in this case to reject the null hypothesis of no trend. But, you might say, we were looking for <em>warming</em>, so we should use a one-sided hypothesis. That halves the <em>p</em>-value to 0.32. But that is still a far cry from even the least stringent (e.g., <em>p </em>= 0.10) thresholds for significance. It is clear that there is no reason to reject the null hypothesis that this is a random time series with no real trend.</p>

<p>Next, let us consider the red noise series of length <em>N</em> = 200 shown earlier in Figure 2.12(2).</p>

<div class="img-center"><img alt="N=200 years of Gaussian 'red noise' with ρ=0.6 with linear trend shown," src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/rednoiseshowntrend_l.gif">
	<div class="img-caption">Figure 2.12(7). <em>N</em>=200 years of Gaussian 'red noise' with ρ=0.6 with linear trend shown.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>As it happens, the trend this time appears nominally greater. The trend line is now given by: <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mover accent="true"> <mi>T</mi> <mo>^</mo> </mover> <mo>=</mo><mn>0.0014</mn><mo>⋅</mo><mi>t</mi><mo>−</mo><mn>0.2875</mn></mrow> </math>, and the regression gives <em>r</em> = 0.0742. So, there is an apparent positive warming trend of 0.14 degrees C per century. That might not seem entirely negligible. And for <em>N</em> = 200 and using a one-sided hypothesis test, <em>r</em> = 0.0742 is statistically significant at the<em> p</em> = 0.148 level according to the online calculator. That does not breach the typical threshold for significance, but it does suggest a pretty high likelihood (15% chance) that we would err by not rejecting the null hypothesis. At this point, you might be puzzled. After all, we did not put any trend into this series! It is simply a random realization of a red noise process.</p>

<div class="box-activity-optional">
	<h4>Self Check</h4>

	<p><strong>So why might the regression analysis be leading us astray this time?</strong></p>
	<textarea cols="100" rows="1"></textarea>

	<p class="toggler">Click for answer.</p>

	<div class="clicktip" id="ctdef">If you said "because we did not account for the effect of autocorrelation" then you are right on target.</div>
</div>

<p>The problem is that our residuals are not uncorrelated. They are red noise. In fact, the residuals looks a lot like the original series itself:</p>

<div class="img-center"><img alt="N=200 years of Gaussian 'red noise'." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/rednoisetrendresid_l.gif">
	<div class="img-caption">Figure 2.12(8). Residuals from linear regression with <em>N</em>=200 years of Gaussian 'red noise' with ρ=0.6</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>This is hardly coincidental; after all, the trend only accounts for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msup> <mi>r</mi> <mn>2</mn> </msup> <mo> </mo><mo>=</mo><msup> <mrow> <mn>0.0742</mn></mrow> <mn>2</mn> </msup> <mo> </mo><mo>=</mo><mn>0.0055</mn></mrow> </math>, i.e., only about half a percent, of the variation in the data. So 99.5% of the variation in the data is still left behind in the residuals. If we calculate the lag-one autocorrelation for the residual series, we get <em>r</em><sub>1</sub> = 0.54. That is, again not coincidentally, very close to the value of ρ = 0.6 we <em>know</em> that we used in generating this series in the first place.</p>

<p>How do we determine if this autocorrelation coefficient is statistically significant? Well, we can treat it like it were a correlation coefficient. The only catch is that we have to use<em> N-1</em> in place of <em>N</em>, because there are only <em>N-1</em> values in the series when we offset it by one time step to form the lagged series required to estimate a lag-one autocorrelation.</p>

<div class="box-activity-optional">
	<h4>Self Check</h4>

	<p><strong>Should we use a one-sided or two-sided hypothesis test?</strong></p>
	<textarea cols="100" rows="1"></textarea>

	<p class="toggler">Click for answer.</p>

	<div class="clicktip" id="ctdef">If you said "one-sided" you are correct.<br>
		After all, we are interested only in whether there is <em>positive</em> autocorrelation in the time series.<br>
		If we found <em>r</em><sub>1</sub> &lt; 0, that would be an entirely different matter, and a complication we will choose to ignore for now.</div>
</div>

<p>If we use the online link and calculate the statistical significance of <em>r</em><sub>1 </sub>= 0.54 with <em>N</em>-<em>1</em> = 199, we find that it is statistically significant at <em>p</em> &lt; 0.001. So, clearly, we cannot ignore it. We have to take it into account.</p>

<p>So, in fact, we have to treat the correlation from the regression<em> r</em> = 0.074 as if it has <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>N</mi><mo>'</mo><mo>=</mo><mrow><mo>(</mo> <mrow> <mn>1</mn><mo>−</mo><mn>0.54</mn></mrow> <mo>)</mo></mrow><mo>/</mo><mrow><mo>(</mo> <mrow> <mn>1</mn><mo>+</mo><mn>0.54</mn></mrow> <mo>)</mo></mrow><mn>200</mn><mo>=</mo><mn>0.30</mn><mrow><mo>(</mo> <mrow> <mn>200</mn></mrow> <mo>)</mo></mrow><mo>=</mo><mn>59.9</mn></mrow> </math> ≈ 60 degrees of freedom, rather than the nominal <em>N</em> = 200 degrees of freedom. Using the interactive online calculator, and replacing <em>N</em> = 200 with the value <em>N'</em> = 60, we now find that a correlation of <em>r</em> = 0.074 is only significant at the<em> p </em>= 0.57 (<em>p</em> = 0.29) for a two-sided (one-sided) test, hardly a level of significance that would cause us to seriously call into doubt the null hypothesis.</p>

<p>At this point, you might be getting a bit exasperated. When, if ever, <em>can </em>we conclude there is a trend? Well, why don't we now consider the case where we know we added a real trend in with the noise, i.e., the example of Figure 2.12(5) where we added a trend of 0.5°C/century to the Gaussian white noise. If we apply our linear regression machinery to this example, we do detect a notable trend:</p>

<div class="img-center"><img alt="Gaussian white noise with added linear trend of 0.5 degrees/century." src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/whitenoisetrend_l.gif">
	<div class="img-caption">Figure 2.12(9). N=200 years of Gaussian white noise with added linear trend of 0.5 degrees/century; the red line shows trend recovered by the linear regression.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>Now, <em>that's</em> a trend - your eye isn't fooling you. The trend line is given by: <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mover accent="true"> <mi>T</mi> <mo>^</mo> </mover> <mo>=</mo><mn>0.0056</mn><mo>⋅</mo><mi>t</mi><mo>−</mo><mn>0.619</mn></mrow> </math>. So there is an apparent positive warming trend of 0.56 °C per century (the 95% uncertainty range that we get for <em>b</em>, i.e., the range <em>b</em>±2 σ<sub><em>b</em></sub>, gives a slope anywhere between 0.32 and 0.79 °C per century, which of course includes the true trend (0.5 °C/century) that we know we originally put in to the series!). The regression gives <em>r</em> = 0.320. For <em>N</em> = 200 and using a one-sided hypothesis test, <em>r</em> = 0.320 is statistically significant at<em> p</em>&lt;0.001 level. And if we calculate the autocorrelation in the residuals, we actually get a small <em>negative</em> value (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <msub> <mi>r</mi> <mn>1</mn> </msub> <mo> </mo><mo>=</mo><mo>−</mo><mn>0.095</mn></mrow> </math>), so autocorrelation of the residuals is not an issue.</p>

<p>Finally, let's look at what happens when the same trend (0.5 °C/century) is added to the random red noise series of Figure 2.12(2), rather than the white noise series of Figure 2.12(1). What result does the regression analysis give now?</p>

<div class="img-center"><img alt="Gaussian red noise with increasing trend line" src="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/rednoisetrend_l.gif">
	<div class="img-caption">Figure 2.12(10). N=200 years of Gaussian red noise with ρ=0.6 and added linear trend of 0.5 degrees/century; the red line shows trend recovered by the linear regression.</div>

	<div class="img-credit">Credit: Michael Mann</div>
</div>

<p>We still recover a similar trend, although it's a bit too large. We know that the true trend is 0.5 degrees/century, but the regression gives: <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mover accent="true"> <mi>T</mi> <mo>^</mo> </mover> <mo>=</mo><mn>0.0064</mn><mo>⋅</mo><mi>t</mi><mo>−</mo><mn>0.793</mn></mrow> </math>. So, there is an apparent positive warming trend of 0.64 °C per century. The nominal 95% uncertainty range that we get for <em>b</em> is 0.37 to 0.92 °C per century, which again includes the true trend (0.5 degrees C/century). The regression gives <em>r</em> = 0.315. For <em>N</em> = 200 and using a one-sided hypothesis test, <em>r</em> = 0.315 is statistically significant at the<em> p</em> &lt; 0.001. So, are we done?</p>

<p>Not quite. This time, it is obvious that the residuals will have autocorrelation, and indeed we have that <em>r</em><sub>1</sub> = 0.539, statistically significant at <em>p</em> &lt; 0.001. So, we will have to use the reduced degrees of freedom <em>N'</em>. We have already calculated <em>N' </em>earlier for ρ = 0.54, and it is roughly <em>N'</em> = 60. Using the online calculator, we now find that the one-sided <em>p</em> = 0.007, i.e., roughly<em> p</em> = 0.01, which corresponds to a 99% significance level. So, the trend is still found to be statistically significant, but the significance is no longer at the astronomical level it was when the residuals were uncorrelated white noise. The effect of the "redness" of the noise has been to make the trend less statistically significant because it is much easier for red noise to have produced a spurious apparent trend from random chance alone. The 95% confidence interval for <em>b</em> also needs to be adjusted to take into account the autocorrelation, though just how to do that is beyond the scope of this course.</p>

<p>Often, residuals have so <em>much</em> additional structure — what is sometimes referred to as <em>heteroscedasticity</em> (how's that for a mouthful?) — that the assumption of simple autocorrelation is itself not adequate. In this case, the basic assumptions of linear regression are called into question and any results regarding trend estimates, statistical significance, etc., are suspect. In this case, more sophisticated methods that are beyond the scope of this course are required.</p>

<p>Now, let us look at some <em>real temperature data</em>! We will use our very own custom online <a href="https://courseware.e-education.psu.edu/courses/meteo101/stat_plotting_tool.swf?filename=STCDecTemp.txt">Linear Regression Tool</a> <span class="print-footnote">[19]</span> written for this course. The demonstration how to use this tool has been recorded in three parts below :</p>

<div class="img-center">
	<div class="video-wrapper"><iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/Qrm_fJRNZFg?rel=0" width="560"></iframe></div>

	<div class="img-caption">
		<div aria-label="expand content" class="toggler">Part 1<br>
			Click for transcript.</div>

		<div aria-label="additional content">
			<p>PRESENTER: OK, we're going to look at an example here. I'm loaning in December average temperatures for State College, Pennsylvania for a 107 year period-- from 1888 to 1994.</p>

			<p>So let's plot out the data. That's what they look like, that's a scatterplot. Or if we like, we can view them in terms of a line plot. If we look at the Statistics tab, it tells you that the average of the temperature is 30.9, just under 31 degrees Fahrenheit. So the average December temperature in State College in Pennsylvania is about a degree Fahrenheit below freezing.</p>

			<p>The standard deviation, 3.95. Just under 4 degrees Fahrenheit. So the fluctuation from year to year in the average December temperature in State College is a fairly sizable 4 degrees Fahrenheit. One year it might be 30, the next year it might be 34, the next year it might be 31, the next year might be 27. That gives you some idea of the fluctuations. And of course we can see those fluctuations here in the plot.</p>

			<p>Now we can calculate a trend line. Let's go to the Linear Regression tool. That calculates the linear trend in the time series. It tells us that there is a trend of 0.25 degrees Fahrenheit warming per year. Or if we want to express that in terms of a century, 2.5 degrees Fahrenheit warming per century. That's the warming trend in State College, Pennsylvania.</p>

			<p>Now the correlation coefficient for that regression is r equals 0.193. If we look that up in the statistics table, put in 107 years for the length of our series, 0.193 for the correlation, and we calculate, the significance tells us that the p-value is 0.023 for a one-tailed test. 0.046 for a two-tailed test.</p>

			<p>So in either case, the correlation, the regression, the trend in the series would be significant at greater than the p equal 0.05 level. It would be significant at the 95% confidence level. Arguably, we should go with the one-tailed test since we're really testing the hypothesis that there is a warming trend in State College.</p>

			<p>Since we know the globe is warming, our hypothesis was unlikely to be that State College showed a cooling trend. We were interested to see if State College showed the warming trend that we know is evident in temperature records around the world. So one could-- in fact, one would typically motivate a one-tailed or a one-sided hypothesis test.</p>

			<p>And so the trend passes that test at the 0.02 level. It's fairly significant.</p>

			<p>If we go back again, we can see the standard error in the slope is 0.012. So if we were to take the value 0.025 and add plus or minus 2 times this number here of 0.012, it would give us the range. The 95% confidence range in the trend. In the slope of this warming trend.</p>
		</div>
	</div>
</div>

<div class="img-center">
	<div class="video-wrapper"><iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/UP-FSwYbx5I?rel=0" width="560"></iframe></div>

	<div class="img-caption">
		<div aria-label="expand content" class="toggler">Part 2<br>
			Click for transcript.</div>

		<div aria-label="additional content">
			<p>PRESENTER: OK, so this slope here-- 0.246-- is roughly twice the standard error in the slope. And in fact, the ratio of the slope to its standard error is something that we call t. And in this case, it's roughly 2. It's a little larger than 2.</p>

			<p>That means that the slope itself is 2 standard errors away from 0, in this case on the positive side. Typically when t is 2 or larger, that signifies a result that's significant at the 0.05 level for a two-tailed test, which is what we see here.</p>

			<p>So in essence, when we see a t value of 2 or larger typically that signifies that the results of the regression are statistically significant, at least for a large sample where n is larger than 100 or so, and as long as we don't have the problem of auto correlation of residuals, which we've talked a bit about before.</p>

			<p>And so our next topic is going to be to talk a little bit about this issue of autocorrelation in this example.</p>
		</div>
	</div>
</div>

<div class="img-center">
	<div class="video-wrapper"><iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/MG_KnBZwcxY?rel=0" width="560"></iframe></div>

	<div class="img-caption">
		<div aria-label="expand content" class="toggler">Part 3<br>
			Click for transcript</div>

		<div aria-label="additional content">
			<p>PRESENTER: Let's look at the residuals. That is to say, what's left over in the data when we remove this regression line. Now we can use the Regression Model tool here. The regression that we've done is where our independent variable is year. Our dependent variable is temperature. And so we can run that regression here.</p>

			<p>And that gives us two things. First of all, it tells us the autocorrelation in the residuals, which as we can see is pretty small. It's minus 0.11. And if we look up the statistical significance of a negative correlation of 0.11 on the order of 100 degrees of freedom, we'll find that it's statistically insignificant. So that means that in this particular case, it doesn't look like we have to worry about the added caveats associated with auto correlation when our residuals do not look like uncorrelated white noise, but instead have this low frequency structure.</p>

			<p>Now we can actually plot those residuals. And I'll make a plot here. I go down to Model Residuals. And so I'm going to plot the residuals as a function of year. I no longer need a trend line here. And that's what we have.</p>

			<p>So when we remove the trend-- we accounted for a statistically significant trend and when we removed that trend-- this is what was left over. These are the residuals. And they look pretty much like Gaussian random white noise, which is good. That means that the results of our regression are basically sound. We fulfilled the basic underlying assumptions that what's left over after we account for the significant trend in the data looks random.</p>
		</div>
	</div>
</div>

<p>You can play around with the temperature data set used in this example using the <a href="https://courseware.e-education.psu.edu/courses/meteo101/stat_plotting_tool.swf?filename=STCDecTemp.txt">Linear Regression Tool</a> <span class="print-footnote">[19]</span></p>
</div></div></div></div>  </div>
<div id="node-209" class="section-3">
  <h1 class="book-heading">Review of Basic Statistical Analysis Methods for Analyzing Data - Part 3</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><h3>Establishing Relationships Between Two Variables</h3>

<p>Another important application of OLS is the comparison of two different data sets. In this case, we can think of one of the time series as constituting the independent variable <em>x</em> and the other constituting the independent variable <em>y</em>. The methods that we discussed in the previous section for estimating trends in a time series generalize readily, except our predictor is no longer time, but rather, some variable. Note that the correction for autocorrelation is actually somewhat more complicated in this case, and the details are beyond the scope of this course. As a general rule, <em>even</em> if the residuals show substantial autocorrelation, the required correction to the statistical degrees of freedom (<em>N' </em>), will be small as long as either one of the two time series being compared has low autocorrelation. Nonetheless, any substantial structure in the residuals remains a cause for concern regarding the reliability of the regression results.</p>

<p>We will investigate this sort of application of OLS with an example, where our independent variable is a measure of El Niño&nbsp;<span style="font-size: 13.0080003738403px; line-height: 20.0063037872314px;">—</span>&nbsp;the so-called <em>Niño 3.4 index</em> — and our dependent variable is December average temperatures in State College, PA.</p>

<p>The demonstration is given in three parts below:</p>

<div class="img-center">
	<div class="video-wrapper"><iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/WJjpZ6DtM-Y" width="560"></iframe></div>

	<div class="img-caption">Demo part 1</div>

	<div aria-label="expand content" class="toggler">Click here for a transcript</div>

	<div aria-label="additional content">
		<p>PRESENTER: Well, now we're going to look at a somewhat different situation where our independent variable is no longer time but it's some quantity. It could be temperature. It could be an index of El Nino, the North Atlantic Oscillation Index.</p>

		<p>So let's look at an example of that sort. We are going to now look at the relationship between El Nino and December temperatures in State College, Pennsylvania. And we can plot out that relationship as a scatterplot. So on the vertical axis we have December temperature in State College. On the horizontal axis our independent variable is the Nino 3.4 index. Negative values indicating La Ninas, positive values indicating El Ninos.</p>

		<p>And the strength of the relationship between the two is going to be determined by the trend line. That describes how winter temperatures in State College, December temperatures in State College depend on El Nino. And so by fitting the regression, we obtain a slope of 0.7397. That means for each unit change in El Nino, in Nino 3.4, we get a 0.74 unit change in temperature. So for a moderate El Nino event where the Nino 3.4 index is in the range of plus 1, that would imply December temperatures in State College that year are 0.74-- degrees Fahrenheit is the scale here-- 0.74 degrees Fahrenheit warmer than usual. And for a modestly strong La Nina where the Nino 3.4 is on the order of minus 1 or so, State College December temperatures would be about 0.74 degrees colder than normal.</p>

		<p>Now the correlation coefficient associated with that linear regression in this case is 0.174. Now we have 107 years here. Our data set, as before, goes from 1888 to 1994. So that's 107 years. We've got a correlation coefficient of 0.174.</p>

		<p>So if we use our table and we take N equal 0.107, r of 0.174, we find that the one-tailed value of P is 0.365. The two-tailed value is 0.073. So if our threshold for significance were P of 0.05, the 95% significance level, then that relationship, a correlation coefficient of 0.174 with 107 years of information, would be significant for a one-tailed test, but it would not pass the 0.05, the 95% significance threshold for a two-tailed test. So we have to ask the question, which is more appropriate here, a one-tailed test or a two-tailed test?</p>

		<p>Now if you had reason to believe that El Nino events warm the Northeastern US, for example, then you might motivate a one-tailed test since only a positive relationship would be consistent with your expectations. But if we didn't know beforehand whether El Ninos had a cooling influence or a warming influence on the Northeastern US, you might argue for a two-tailed test. So whether or not the relationship is significant at the P equal 0.05 level is going to depend on which type of hypothesis test we're able to motivate in this case.</p>
	</div>

	<div class="img-credit"></div>
</div>

<div class="img-center">
	<div class="video-wrapper"><iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/3rd0UoNqd2I" width="560"></iframe></div>

	<div class="img-caption">Demo part 2</div>

	<div aria-label="expand content" class="toggler">Click here for a transcript</div>

	<div aria-label="additional content">
		<p>PRESENTER: OK, well, let's continue with this analysis. Now, what I'm going to do here is plot instead the temperature as a function of year. That's plot number 1. And we no longer want a trend line here. That's blue. That's the State College December temperatures.</p>

		<p>And now, for plot number 2, I am going to plot the Nino 3.4 index for that year. And I'll use axis b to put them on the same scales. So here we can see the two series. Blue is the December temperatures. Red is the Nino 3.4 index. And you can see that in various individual years, there does seem to be a relationship where large positive departures of the Nino 3.4 index are associated with warm Decembers, and large negative departures are associated with cold temperatures.</p>

		<p>So we can see visually that relationship that we also saw when we plotted the two variables in a two-dimensional scatterplot, and looked at the slope of the line relating the two data sets. Here now, we're looking at the time series of the two data sets. And we can see some of that positive covariance, if you will, that there does appear to be a positive relationship. Although, we already know it's a fairly weak relationship.</p>

		<p>Now, let's do the formal regression. So I'm going to take away the El Nino series. So here we've got State College December temperatures in blue. Now, our regression model is going to use the Nino 3.4 index as our independent variable, as a predictor of State College December temperatures, our dependent variable.</p>

		<p>We'll run the linear regression. There is the slope. 0.74 is the coefficient that describes the relationship in how temperature depends on the Nino 3.4 index. It's positive. We already saw that the slope was positive. There's also a constant term that we're not going to worry about too much here. What we're really interested in is the slope of the regression line that describes how changes in temperature depend on changes in the Nino 3.4 index.</p>

		<p>And as we've seen, that 0.74 implies that for a unit increase in Nino 3.4, in an anomaly of plus 1 on the Nino 3.4 scale, we get a temperature for December that on average is 0.74 degrees Fahrenheit warmer than average.</p>

		<p>The R-squared value is 0.0301. Well, if we take 0.0301, 0.0301, and take the square root of that, that's the r value of 0.1734. And we know it's a positive correlation because the slope is positive.</p>

		<p>We already looked up the statistical significance of that number, and we found that for a one-sided hypothesis test, that the relationship is significant at the 0.05 level. But if we were using a two-sided significant criterion hypothesis test-- that is to say, if we didn't know a priori whether we had reason to believe that El Nino's warm or cool State College December temperatures-- then the relationship would not quite be statistically significant.</p>

		<p>So we've calculated the linear model. We can now plot it. So now, I'm going to plot year in model output on the same scale. And so now, the red curve is showing us the component of variation in the blue curve that can be explained by El Nino.</p>

		<p>And we can see it's a fairly small component. It's small compared to the overall level of variability in December State College temperatures, which vary by as much as plus or minus 4 degrees or so Fahrenheit. The standard deviation is close to [AUDIO OUT]</p>
	</div>

	<div class="img-credit"></div>
</div>

<div class="img-center">
	<div class="video-wrapper"><iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/FDgcqB_0LzY" width="560"></iframe></div>

	<div class="img-caption">Demo part 3</div>

	<div aria-label="expand content" class="toggler">Click here for a transcript</div>

	<div aria-label="additional content">
		<p>PRESENTER: OK, so continuing where we left off. The red curve is showing us the component of the variation in December State College temperatures that can be explained by El Nino. If in a particularly strong El Nino year, where the Nino 3.4 Index is say as large as plus two, we get a December temperature that's about a 1.5 Fahrenheit above average. That is to say twice that 0.74 degrees effect that we get for a one unit change in Nino 3.4.</p>

		<p>For a particularly strong La Nina event which would correspond to a negative Nino 3.4 anomaly of say negative 2 or so, we would get a 1.5 Fahrenheit cooling effect on State College December temperatures. So the influence of El Nino is small compared to the overall variability in the series. But it is statistically significant.</p>

		<p>At least if we are able to motivate a one sided hypothesis test, if we had reason a priori to believe that El Nino events warm State College temperatures in the winter, then the regression gives us a result that's significant at the 0.05 level. The standard threshold for statistical significance.</p>

		<p>OK. So it may not be that satisfying. We're not explaining a large amount of variation in the data. But we do appear to be explaining a statistically significant fraction of variability in the data.</p>

		<p>Now finally, let's look at the trend. Sorry. Let's look at the residuals from that regression. And what I'll do is, I will get rid of these graphs that we have right now. And I'm just going to plot the model residuals as a function of time.</p>

		<p>That's what they look like. There isn't a whole lot of obvious structure. And in fact, if you go back to the regression model tab, and we look at the value of the lag 1 auto-correlation coefficient, we see that it's minus .09. That's quite-- it's slightly negative. It's quite small, close to zero.</p>

		<p>If we look up the statistical significance, it's not going to be even remotely significant. So we don't have to worry about auto correlation influencing our estimate of statistical significance. We also don't have much evidence here of the sort of low frequency structure in the residuals that might cause us worry.</p>

		<p>So the nominal results of our regression analysis appear valid. And again, if we were to invoke a one sided hypothesis test, we would have found a statistically significant-- albeit a weak-- influence of El Nino on State College December temperatures.</p>
	</div>

	<div class="img-credit"></div>
</div>

<p style="text-align: left;">You can play around with the data set used in this example using this link: <a href="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/from_DBabb/stat_plotting_tool.swf">Explore Using the File testdata.txt</a> <span class="print-footnote">[20]</span></p>
</div></div></div></div>  </div>
<div id="node-126" class="section-3">
  <h1 class="book-heading">Problem Set #1</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><h3>Activity: Statistical Analysis of Climate Data</h3>

<div class="box-note">
	<p><strong>NOTE: </strong>For this assignment, you will need to record your work on a word processing document. Your work must be submitted in Word (.doc or .docx), or PDF (.pdf) format.</p>
</div>

<p>For this activity, you will use the <strong>Linear Regression</strong> application below to perform basic statistical analyses of climate data. The data we will use are global temperature anomalies and Niño 3.4 index, both measured in °C. You need to:</p>

<ul>
	<li>Determine historical trends in global temperatures and determine if there has been an increase in the trend.</li>
	<li>Analyze the influence of El Niño on global temperatures.</li>
</ul>

<p><strong><a href="https://courseware.e-education.psu.edu/courses/meteo469/stat_plotting_tool.swf?filename=assignment1_sp2019.txt">Link to Linear Regression Tool</a> <span class="print-footnote">[21]</span></strong></p>
<!-- <p><strong><a href="https://courseware.e-education.psu.edu/courses/meteo469/stat_plotting_tool.swf?filename=assignment1.txt">Link to Linear Regression Tool</a> <span class="print-footnote">[22]</span></strong></p> -->

<p><strong>Note:</strong> The Linear Regression tool may not work in the Chrome browser, you may need to use Firefox, Internet Explorer, or Microsoft Edge.</p>

<h4>Directions</h4>

<ol>
	<li>First, save the <a href="https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/PS1_worksheet_Sp2019.doc">Problem Set #1 Worksheet</a> <span class="print-footnote">[23]</span> to your computer. You will use this word processing document to electronically record your work in the remaining steps.

		<ul>
			<li>Save the worksheet to your computer by right-clicking on the link above and selecting "Save link as..."</li>
			<li>The worksheet is in Microsoft Word format. You can use either Word or Google Docs (free) to work on this assignment. You will submit your worksheet at the end of the activity, so it must be in Word (.doc or .docx) or PDF (.pdf) format so the instructor can open it.</li>
			<li>Please show your work!&nbsp; When you are explicitly asked to create plots in a question, please cut-and-paste graphics and the output from the screen (e.g., by first printing the output to a pdf file and then directly inserting into the worksheet) to submit along with your discussion and conclusions.&nbsp;</li>
		</ul>
	</li>
	<li>Use the Linear Regression plotting tool to create a line plot of global temperature anomalies vs. time over the full 168-year period (1850 - 2017). Determine the basic statistics of the time series, i.e., the mean and standard deviation. If the mean is not zero, can you guess the 30 year base period that was used to calculate the anomalies? To do that, note that by definition, the mean of the base period used to calculate anomalies should be zero. Visually determine the year where the temperature anomalies graph crosses zero. Zoom in on different 30-year intervals around that year and use Viewport Data under the Statistics tab to view the mean for each selected 30-year sub-set of data, until you find a period for which the mean is closest to zero.</li>
	<li>Evaluate the linear trend in global temperature anomalies over the full 168-year period (1850 - 2017) following the steps below.&nbsp; (A) Add a trend line to the plot of global temperature anomalies vs. time over the full 168-year period: use the Trend Lines tab. Determine the slope of the linear regression line, b, in ºC/century and the correlation coefficient, r. As a side exercise, calculate the overall warming trend in temperature over the 1850-2017 period by multiplying the slope by the number of years in the period.&nbsp; (B) Assess statistical significance of the linear trend in global temperature anomalies without considering autocorrelation: use the <a href="http://vassarstats.net/tabs.html">online Statistical Calculator tool</a> <span class="print-footnote">[18]</span> from Lesson 2, Statistical Analysis Part 2 to calculate the p-value for the number of samples, N, and the correlation coefficient, r, from part A. Interpret the p-value. Use the standard error of the slope, Sb, to calculate 95% confidence interval for the slope as b ±2Sb, and report the calculated warming range in ºC/century. (C) Determine lag-one autocorrelation coefficient for the residuals, ρ. To do that, run the regression model using the Regression Model tab: select Model Parameters = year, Target Observation = Temp Anom. Plot the residuals: in the Plot Settings tab, select year for X and Model Residuals for Y. Check whether the autocorrelation is statistically significant using the Statistical Calculator. Remember that lag-one autocorrelation is simply correlation between the original data and an exact copy of the data but shifted by one time step, so the number of samples, N, is decreased by one; and the correlation coefficient, r, should be substituted by autocorrelation coefficient, ρ. Interpret the p-value. (D) Reassess statistical significance of the linear trend in the global temperature anomalies, taking into account autocorrelation of the residuals. Remember that in the presence of a significant autocorrelation, the actual number of samples, N, must be replaced by the degrees of freedom, N': use formula (2) from Lesson 2 to calculate N'. Use the Statistical Calculator to calculate the p-value for N = N' and r from part (A). Interpret the p-value.&nbsp; (E) Look closely at the plot of the residuals that you created in part (C). Do you see evidence of heteroscedasticity (additional structure superimposed on the random fluctuations)? Do you think that the hypothesis of a simple linear warming trend in this data series is appropriate or not?</li>
	<li>Test the hypothesis that there is a difference in trend over two sub-periods: the first 110 years and the final 58 years. Follow the steps below. (A) Use the Plot Settings tab to plot the entire data series and zoom in to select 1850-1959 sub-period. Select Viewport in the Trend Lines tab to perform linear regression for the sub-period. Determine the slope of the linear regression line, b, in ºC/century and the correlation coefficient, r. Use the standard error of the slope, Sb, to calculate 95% confidence interval for the slope in ºC/century. (B) Repeat the analysis for the 1960-2017 sub-period.&nbsp; (C) Determine whether trends are statistically different: you need to check whether the 95% confidence intervals for the two sub-periods overlap. Based on your results, has global warming accelerated over the past 58 years? What important caveat about the 95% confidence intervals was not taken into account in our analysis?</li>
	<li>Is there a statistically significant influence of El Niño on global temperatures? (A) Use the Plot Settings tab to plot global temperature anomalies (Temp Anom) over time (Plot #1) and then Niño 3.4 index (Niño) over time (Plot #2) on the same plot. Determine the number of years, N, in the time interval over which the two data series overlap. This is the number of samples you will use in the analyses below. (B) Plot the relationship between Niño 3.4 index and global temperature anomaly: use the Plot Settings tab to plot Niño 3.4 index (Niño) on the X-axis and global temperature anomalies (Temp Anom) on the Y-axis. Determine the slope of the linear regression line, b (in °C change in global temperature per a unit change in Niño 3.4 index) and the correlation coefficient, r. Assess statistical significance of the linear trend without accounting for autocorrelation. (C) Plot model residuals over time and discuss whether heteroscedasticity of the regression model residuals is a point of concern in your analysis.</li>
	<li>Given that there is a 90% chance of moderate El Nino conditions this year, how do you expect ENSO to influence this year's global temperature? ENSO – El Nino-Southern Oscillation – is a climate pattern of oscillation between El Nino events (the positive phase, i.e. Nino 3.4 index above average) and La Nina events (the negative phase, i.e. Nino 3.4 index below average).&nbsp; Using a moderately positive value of the Nino 3.4 index [0.75] during the historical time period used for the regression equation from question (5), determine the temperature anomaly predicted by the regression model for this most negative value.&nbsp; By comparing this temperature anomaly to the temperature anomaly expected in neutral (i.e., Nino 3.4 index = 0) conditions, estimate the perturbation of global temperatures expected in moderate El Nino events.&nbsp;&nbsp;&nbsp;</li>
	<li>Save your word processing document as either a Microsoft Word or PDF file in the following format: PS1_AccessAccountID_LastName.doc (or .pdf).
		<p>For example, student Elvis Aaron Presley's file would be named "PS1_eap1_presley.doc". This naming convention is important, as it will help the instructor match each submission with the right student!</p>
	</li>
</ol>

<h4>Submitting your work</h4>

<p>Upload your file to the "Problem Set #1" assignment in Canvas by the due date indicated in the Syllabus.</p>

<h4>Grading rubric</h4>

<p>The instructor will use the general <a href="https://www.e-education.psu.edu/meteo469/node/243">grading rubric for problem sets</a> <span class="print-footnote">[24]</span> to grade this activity.</p>

<p>Solutions will be uploaded to <em>Lesson 2: Climate Observations, Part 1</em> in<em> Canvas </em>after the due date.</p>

<div id="cke_pastebin" style="position: absolute; top: 875.1px; width: 1px; height: 1px; overflow: hidden; left: -1000px;"></div>
</div></div></div></div>  </div>
<div id="node-124" class="section-3">
  <h1 class="book-heading">Lesson 2 Summary</h1>
  <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><div class="tex2jax"><p>In this lesson, we reviewed key observations that detail how our atmosphere and climate are changing. We have seen that:</p>

<ul>
	<li>Greenhouse gas concentrations, including atmospheric CO<sub>2</sub> and methane, are increasing dramatically and these increases are associated with human activity;</li>
	<li>The surface of the Earth is warming and certain regions (e.g., the Arctic) are warming faster than others, consistent, as we will see, with expectations from climate model projections;</li>
	<li>The vertical pattern of the warming indicates that the surface and lower atmosphere (troposphere) are warming, while the atmosphere is cooling at altitude (in the stratosphere), a pattern that is consistent with greenhouse warming, but not with the natural factors such as solar output changes;</li>
	<li>There is a complicated pattern of changes in rainfall patterns around the globe, with some regions becoming wetter while other regions become drier;</li>
	<li>Despite the heterogeneous pattern of changes in rainfall, there is a trend towards more widespread drought, consistent with the additional impact of warming on evaporation from the soil.</li>
</ul>

<p>We also learned how to analyze basic relationships in observational data, including:</p>

<ul>
	<li>How to assess whether or not there is a statistically significant trend over time in a data series;</li>
	<li>How to assess whether or not there is a statistically significant relationship between two distinct data series.</li>
</ul>

<p>In our next lesson, we will look at some additional types and sources of observational climate data, and we will explore some additional tools for analyzing data.</p>

<h3>Reminder - Complete all of the lesson tasks!</h3>

<p>You have finished Lesson 2. Double-check the list of requirements on the first page of this lesson to make sure you have completed all of the activities listed there before beginning the next lesson.</p>
</div></div></div></div>  </div>
</div>
</div>
    <div class="print-footer">
</div>
    <hr class="print-hr" />
          <div class="print-source_url">
        <strong>Source URL:</strong> https://www.e-education.psu.edu/meteo469/node/118      </div>
        <div class="print-links"><p><strong>Links</strong><br />[1] https://www.ipcc.ch/report/ar5/wg1/<br />
[2] https://www.ipcc.ch/site/assets/uploads/2018/02/WG1AR5_SPM_FINAL.pdf<br />
[3] http://earthobservatory.nasa.gov/Features/Revelle/revelle.php<br />
[4] http://www.harvardsquarelibrary.org/biographies/roger-revelle/<br />
[5] http://scrippsco2.ucsd.edu/history_legacy/charles_david_keeling_biography<br />
[6] http://www.esrl.noaa.gov/<br />
[7] http://www.esrl.noaa.gov/research/themes/carbon/<br />
[8] http://www.esrl.noaa.gov<br />
[9] http://data.giss.nasa.gov/gistemp/<br />
[10] http://www.giss.nasa.gov/about/<br />
[11] http://data.giss.nasa.gov/gistemp/animations/<br />
[12] http://www.realclimate.org/index.php/archives/2008/03/the-global-cooling-mole/<br />
[13] https://www.e-education.psu.edu/meteo469/node/203<br />
[14] https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/PrecipTrendsIPCC_large.gif<br />
[15] https://www.e-education.psu.edu/meteo469/node/152<br />
[16] http://en.wikipedia.org/wiki/Carl_Friedrich_Gauss<br />
[17] http://en.wikipedia.org/wiki/Ordinary_least_squares<br />
[18] http://vassarstats.net/tabs.html<br />
[19] https://courseware.e-education.psu.edu/courses/meteo101/stat_plotting_tool.swf?filename=STCDecTemp.txt<br />
[20] https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/from_DBabb/stat_plotting_tool.swf<br />
[21] https://courseware.e-education.psu.edu/courses/meteo469/stat_plotting_tool.swf?filename=assignment1_sp2019.txt<br />
[22] https://courseware.e-education.psu.edu/courses/meteo469/stat_plotting_tool.swf?filename=assignment1.txt<br />
[23] https://www.e-education.psu.edu/meteo469/sites/www.e-education.psu.edu.meteo469/files/lesson02/PS1_worksheet_Sp2019.doc<br />
[24] https://www.e-education.psu.edu/meteo469/node/243<br />
</p></div>
      </body>

<!-- Mirrored from www.e-education.psu.edu/meteo469/print/book/export/html/118 by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 29 Jan 2019 19:47:36 GMT -->
</html>
